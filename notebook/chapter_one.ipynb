{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f6d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd452d81",
   "metadata": {},
   "source": [
    "## General formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffcbfa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          period respondent                                 respondent-name  \\\n",
      "0  2025-12-31T08        AVA                              Avista Corporation   \n",
      "1  2025-12-31T08       BANC      Balancing Authority of Northern California   \n",
      "2  2025-12-31T08       BPAT                 Bonneville Power Administration   \n",
      "3  2025-12-31T08        CAL                                      California   \n",
      "4  2025-12-31T08       CHPD  Public Utility District No. 1 of Chelan County   \n",
      "\n",
      "  type                  type-name  \n",
      "0   DF  Day-ahead demand forecast  \n",
      "1   DF  Day-ahead demand forecast  \n",
      "2   DF  Day-ahead demand forecast  \n",
      "3   DF  Day-ahead demand forecast  \n",
      "4   DF  Day-ahead demand forecast  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# get EIA API key from environment variable\n",
    "EIA_API_KEY = os.getenv(\"EIA_API_KEY\")\n",
    "EIA_BASE_URL = \"https://api.eia.gov/v2/\"\n",
    "api_path = 'electricity/rto/region-data/'\n",
    "get_request = EIA_BASE_URL + api_path +\\\n",
    "    'data/&data[]=value' + '?api_key=' + EIA_API_KEY \n",
    "\n",
    "response = requests.get(get_request)\n",
    "data = response.json()\n",
    "df = pd.DataFrame(data['response']['data'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687475c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          period respondent                                 respondent-name  \\\n",
      "0  2025-12-31T08        AVA                              Avista Corporation   \n",
      "1  2025-12-31T08       BANC      Balancing Authority of Northern California   \n",
      "2  2025-12-31T08       BPAT                 Bonneville Power Administration   \n",
      "3  2025-12-31T08        CAL                                      California   \n",
      "4  2025-12-31T08       CHPD  Public Utility District No. 1 of Chelan County   \n",
      "\n",
      "  type                  type-name  \n",
      "0   DF  Day-ahead demand forecast  \n",
      "1   DF  Day-ahead demand forecast  \n",
      "2   DF  Day-ahead demand forecast  \n",
      "3   DF  Day-ahead demand forecast  \n",
      "4   DF  Day-ahead demand forecast  \n"
     ]
    }
   ],
   "source": [
    "# Extract the API key from the environment variable\n",
    "eia_api_key = os.getenv('EIA_API_KEY')\n",
    "\n",
    "# Create the full URL path\n",
    "api_url = \"https://api.eia.gov/v2/\"\n",
    "api_path = \"electricity/rto/region-data/\"\n",
    "api_url_path = api_url + api_path + \"data/&data[]=value\"\n",
    "full_path = api_url_path + \"?api_key=\" + eia_api_key\n",
    "\n",
    "# Make the request\n",
    "data = requests.get(full_path).json()\n",
    "\n",
    "df = pd.DataFrame(data[\"response\"][\"data\"])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3c0dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['period', 'respondent', 'respondent-name', 'type', 'type-name'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "df = pd.read_csv('data/data.csv')\n",
    "ts = df[['period', 'value']]\n",
    "ts['period'] = pd.to_datetime(ts['period'])\n",
    "ts = ts.sort_values('period')\n",
    "\n",
    "ts = ts.rename(columns={'period': 'ds', 'value': 'y'})\n",
    "ts['unique_id'] = 1        \n",
    "\n",
    "from statsforecast import StatsForecast\n",
    "\n",
    "fig = StatsForecast.plot(ts, engine=\"plotly\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b1368",
   "metadata": {},
   "source": [
    "- data preparation\n",
    "- model(s) training\n",
    "- model(s)  evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd218b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "        DynamicOptimizedTheta, SeasonalNaive, AutoARIMA, HoltWinters, MSTL\n",
    "    )\n",
    "\n",
    "from utilsforecast.plotting import plot_series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56112eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_length = 72\n",
    "train_end = end-datetime.timedelta(hours=test_length)\n",
    "train = ts[(ts['ds'] <= train_end)]\n",
    "test = ts[(ts['ds'] > train_end)]\n",
    "\n",
    "plot_series(train, engine=\"plotly\")\n",
    "plot_series(test, engine=\"plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate models with hourly seasonality\n",
    "from statistics import mean\n",
    "\n",
    "from cv2 import sqrt\n",
    "\n",
    "\n",
    "auto_arima = AutoARIMA()\n",
    "s_naive = SeasonalNaive(season_length=24)\n",
    "theta = DynamicOptimizedTheta(season_length=24)\n",
    "\n",
    "# instantiate models with daily and weekly seasonality\n",
    "mstl1 = MSTL(season_length=[24, 24*7],\n",
    "             trend_forecaster=AutoARIMA(),\n",
    "             alias=\"MSTL-ARIMA_trend\")\n",
    "\n",
    "mstl2 = MSTL(season_length=[24, 24*7],\n",
    "             trend_forecaster=HoltWinters(),\n",
    "             alias=\"MSTL-HW_trend\")\n",
    "\n",
    "# store models in a list\n",
    "stats_models = [auto_arima, s_naive, theta, mstl1, mstl2]\n",
    "\n",
    "# instantiate StatsForecast object\n",
    "sf = StatsForecast(models=stats_models, \n",
    "                   freq='H',\n",
    "                   fallback_model=AutoARIMA(), \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# create forecasts\n",
    "forecasts = sf.forecast(df=train, \n",
    "                        h=72, \n",
    "                        level=95 #[80, 95]\n",
    "                        )\n",
    "\n",
    "# plot forecasts\n",
    "p = sf.plot(test, forecasts, engine=\"plotly\", level=[95])\n",
    "p.update_layout(weight=400)\n",
    "p.show()\n",
    "\n",
    "# model evaluation\n",
    "def mape(y_true, y_pred):\n",
    "    mape = mean(abs((y_true - y_pred) / y_true))\n",
    "    return mape\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    rmse = sqrt(mean((y_true - y_pred) ** 2))\n",
    "    return rmse\n",
    "\n",
    "def coverage(y_true, lower_bound, upper_bound):\n",
    "    coverage = mean((y_true >= lower_bound) & (y_true <= upper_bound))\n",
    "    return coverage\n",
    "\n",
    "# merge forecasts with test set\n",
    "fc = forecasts.merge(test, on=['unique_id', 'ds'], how='left')\n",
    "fc_performance = None\n",
    "\n",
    "for i in [str(m) for m in stats_models]:\n",
    "    m = mape(y = fc['y'], y_pred = fc[i])\n",
    "    r = rmse(y = fc['y'], y_pred = fc[i])\n",
    "    c = coverage(y = fc['y'], \n",
    "                 lower_bound = fc[f'{i}_lower_95'], \n",
    "                 upper_bound = fc[f'{i}_upper_95'])\n",
    "    perf = {'model': i, \n",
    "            'mape': m, \n",
    "            'rmse': r, \n",
    "            'coverage': c}\n",
    "    if fc_performance is None:\n",
    "        fc_performance = pd.DataFrame(perf, index=[0])\n",
    "    else:\n",
    "        fc_performance = pd.concat([fc_performance, pd.DataFrame(perf, index=[0])])\n",
    "\n",
    "fc_performance.reset_index(drop=True, inplace=True)\n",
    "print(fc_performance.sort_values('rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using mlforecast package\n",
    "from mlforecast import MLForecast\n",
    "import datetime\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mlforecast.utils import PredictionIntervals\n",
    "\n",
    "# Define the ML models\n",
    "ml_models = [LGBMRegressor(),  XGBRegressor(), LinearRegression()]\n",
    "\n",
    "# Set up the MLForecast object with models and frequency\n",
    "mlf = MLForecast(\n",
    "    models= ml_models,  \n",
    "    freq='h', \n",
    "    lags=list(range(1, 24)), \n",
    "    date_features=['year', 'month', 'day', 'dayofweek', 'quarter', 'week', 'hour'])\n",
    "\n",
    "\n",
    "ml_models = [LGBMRegressor(), XGBRegressor(), LinearRegression()]\n",
    "\n",
    "mlf = MLForecast(\n",
    "    models= ml_models,  \n",
    "    freq='h', \n",
    "    lags=list(range(1, 24)), \n",
    "    date_features=['year', 'month', 'day', 'dayofweek', 'quarter', 'week', 'hour'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlf.fit(df=train,  fitted=True, \n",
    "prediction_intervals=PredictionIntervals(n_windows=5, h=72, method=\"conformal_distribution\"))\n",
    "\n",
    "# Generate forecasts for the next 72 hours with 95% confidence\n",
    "ml_forecast = mlf.predict(72, level=[95])\n",
    "\n",
    "# print(ml_forecast.head())\n",
    "\n",
    "#Â Combine the data\n",
    "fc = ml_forecast.merge(test, how=\"left\", on=\"ds\")\n",
    "fc_performance = None\n",
    "\n",
    "for model in [\"LGBMRegressor\", \"XGBRegressor\", \"LinearRegression\"]:\n",
    "    m = mape(y=fc[\"y\"], yhat=fc[model])\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    r = rmse(y=fc[\"y\"], yhat=fc[model])\n",
    "    c = coverage(y=fc[\"y\"], lower=fc[model + \"-lo-95\"], upper=fc[model + \"-hi-95\"])\n",
    "\n",
    "    perf = {\"model\": model, \"mape\": m, \"rmse\": r, \"coverage\": c}\n",
    "    if fc_performance is None:\n",
    "        fc_performance = pd.DataFrame([perf])\n",
    "    else:\n",
    "        fc_performance = pd.concat([fc_performance, pd.DataFrame([perf])])\n",
    "\n",
    "# Sort the performance metrics by rmse\n",
    "print(fc_performance.sort_values(\"rmse\"))\n",
    "\n",
    "# Plot the forecast results\n",
    "fig = plot_series(test, ml_forecast, level=[95], engine=\"plotly\").update_layout(height=400)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
