{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f645dd41",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "Backtesting using expanding window approach with multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import Differences\n",
    "from mlforecast.utils import PredictionIntervals\n",
    "from window_ops.expanding_window import expanding_mean\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from utilsforecast.plotting import plot_series\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "df = pd.read_csv('data/data.csv')\n",
    "ts = df[['period', 'value']]\n",
    "ts['period'] = pd.to_datetime(ts['period'])\n",
    "ts = ts.sort_values('period')\n",
    "\n",
    "ts = ts.rename(columns={'period': 'ds', 'value': 'y'})\n",
    "\n",
    "\n",
    "end = ts['ds'].max()\n",
    "start = end - datetime.timedelta(hours = 24*31*25)\n",
    "ts = ts[(ts['ds'] >= start)]\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1'\n",
    "\n",
    "# define models\n",
    "ml_models = {\n",
    "    'lightgbm': LGBMRegressor(n_estimators=500, verbosity=-1),\n",
    "    'xgboost': XGBRegressor(),\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'mlp': MLPRegressor(max_iter=500),\n",
    "    'random_forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "mlf = MLForecast(\n",
    "    models=ml_models,\n",
    "    freq='h',\n",
    "    lags=list(range(1,24)),\n",
    "    date_features=['month', 'day', 'dayofweek', 'week', 'hour', # seasonal features\n",
    "                   'quarter'])\n",
    "\n",
    "# window setting\n",
    "partitions =10\n",
    "step_size = 24\n",
    "h=72\n",
    "\n",
    "# prediction intervals\n",
    "n_windows = 5\n",
    "method = 'conformal_distribution'\n",
    "pi = PredictionIntervals(h=h,\n",
    "                         n_windows= n_windows,\n",
    "                         method=method)\n",
    "levels = [95]\n",
    "\n",
    "# backtesting with expanding window\n",
    "bkt_df = mlf.cross_validation(\n",
    "    df = ts,\n",
    "    h = h,\n",
    "    step_size = step_size,\n",
    "    n_windows=partitions,\n",
    "    prediction_intervals=pi,\n",
    "    levels=levels           \n",
    ")\n",
    "\n",
    "\n",
    "partitions_labels = bkt_df[\"cutoff\"].unique()\n",
    "ts_sub = ts[ts[\"ds\"] > ts[\"ds\"].max() - datetime.timedelta(hours=24 * 7)]\n",
    "\n",
    "# Create subplots with four rows (one for each partition)\n",
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots(rows=4, cols=1, subplot_titles=[\"Partitions: \" + str(i) for i in partitions_labels])\n",
    "\n",
    "r = 1  \n",
    "\n",
    "for i in partitions_labels:\n",
    "    if r == 1:\n",
    "        showlegend = True\n",
    "    else:\n",
    "        showlegend = False\n",
    "    bkt_sub = bkt_df[bkt_df[\"cutoff\"] == i]\n",
    "    # Add actual values to the plot\n",
    "    fig.append_trace(go.Scatter(x=ts_sub[\"ds\"], y=ts_sub[\"y\"], legendgroup=\"actual\", showlegend=showlegend, \n",
    "                                mode='lines', name='Actual', line=dict(color='#023047', width=2)), row=r, col=1)\n",
    "    # Add k-nearest neighbors predictions\n",
    "    fig.append_trace(go.Scatter(x=bkt_sub[\"ds\"], y=bkt_sub[\"knn\"], mode='lines', name='k-nearest neighbors', \n",
    "                                legendgroup=\"knn\", showlegend=showlegend, line=dict(color='#2a9d8f', width=1.5, dash=\"dash\")), row=r, col=1)\n",
    "    # Add Multi-layer Perceptron predictions\n",
    "    fig.append_trace(go.Scatter(x=bkt_sub[\"ds\"], y=bkt_sub[\"mlp\"], mode='lines', name='Multi-layer Perceptron', \n",
    "                                legendgroup=\"mlp\", showlegend=showlegend, line=dict(color='#0077b6', width=1.5, dash=\"dot\")), row=r, col=1)\n",
    "    # Add ElasticNet predictions\n",
    "    fig.append_trace(go.Scatter(x=bkt_sub[\"ds\"], y=bkt_sub[\"enet\"], mode='lines', name='ElasticNet', \n",
    "                                legendgroup=\"enet\", showlegend=showlegend, line=dict(color='#ffc8dd', width=1.5, dash=\"dot\")), row=r, col=1)\n",
    "    r = r + 1 \n",
    "\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dbad4d",
   "metadata": {},
   "source": [
    "### Model Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformart backtesting results\n",
    "cutoff = bkt_df[\"cutoff\"].unique()\n",
    "partitions_mapping = pd.DataFrame({\n",
    "    'cutoff': cutoff,\n",
    "    'partition': range(1, len(cutoff)+1)\n",
    "})\n",
    "\n",
    "model_label = ['lightgbm', 'xgboost', 'ridge', 'lasso', 'linear_regression', 'mlp', 'random_forest']\n",
    "model_name = ['LGBMRegressor', 'XGBRegressor', 'Ridge', 'Lasso', 'LinearRegression', 'MLPRegressor', 'RandomForestRegressor']\n",
    "models_mapping = pd.DataFrame({\n",
    "    'model_label': model_label,\n",
    "    'model_name': model_name\n",
    "})\n",
    "\n",
    "bkt_long = bkt_df.melt(\n",
    "    bkt_df,\n",
    "    id_vars = ['unique_id', 'ds', 'cutoff', 'y'],\n",
    "    value_vars = model_label + [f'{model}-lo-95' for model in model_label] + [f'{model}-hi-95' for model in model_label],\n",
    "    var_name = 'model_label',\n",
    "    value_name = 'value'\n",
    ")\n",
    "\n",
    "def split_model_confidence(model_name):\n",
    "    if '-lo-95' in model_name:\n",
    "        return model_name.replace('-lo-95', ''), 'lower'\n",
    "    elif '-hi-95' in model_name:\n",
    "        return model_name.replace('-hi-95', ''), 'upper'\n",
    "    else:\n",
    "        return model_name, 'forecast'\n",
    "    \n",
    "bkt_long['model_label'],\\\n",
    "bkt_long['type'] = zip(*bkt_long['model_label'].map(split_model_confidence)) \n",
    "\n",
    "bkt_long = bkt_long.merge(partitions_mapping, on='cutoff', how='left')\n",
    "bkt =(bkt_long\n",
    "      .pivot(index=['unique_id', 'ds', 'cutoff', 'y', 'partition', 'model_label'],\n",
    "                   columns='type',\n",
    "                   values='value')\n",
    "      .reset_index()   \n",
    "      .merge(models_mapping, on='model_label', how='left')\n",
    ")\n",
    "\n",
    "# model evaluation\n",
    "def mape(y_true, y_pred):\n",
    "    mape = mean(abs((y_true - y_pred) / y_true))\n",
    "    return mape\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    rmse = sqrt(mean((y_true - y_pred) ** 2))\n",
    "    return rmse\n",
    "\n",
    "def coverage(y_true, lower_bound, upper_bound):\n",
    "    coverage = mean((y_true >= lower_bound) & (y_true <= upper_bound))\n",
    "    return coverage\n",
    "\n",
    "def score(df):\n",
    "    mape_score = mape(y = df[\"y\"], yhat = df[\"forecast\"])\n",
    "    rmse_score = rmse(y = df[\"y\"], yhat = df[\"forecast\"])\n",
    "    coverage_score = coverage(y = df[\"y\"], lower = df[\"lower\"], upper = df[\"upper\"])\n",
    "    cols = [\"mape\", \"rmse\", \"coverage\"]\n",
    "    df = pd.Series([mape_score, rmse_score,  coverage_score], index=cols)\n",
    "    return df\n",
    "\n",
    "score_df = (bkt\n",
    "            .groupby(['unique_id', 'model_label', 'model_name', 'partition'])[['unique_id', \n",
    "                                                                               'model_label',\n",
    "                                                                               'model_name',\n",
    "                                                                               'partition',\n",
    "                                                                               'y', \n",
    "                                                                               'forecast', 'lower', 'upper']]\n",
    "            .apply(score)\n",
    "            .reset_index()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746bdd6",
   "metadata": {},
   "source": [
    "mlflow workflow\n",
    "1. Define experiment\n",
    "2. run experiment\n",
    "3. log parameters\n",
    "4. log KPIs\n",
    "5. compare and analyze experiments results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0caa1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import datetime\n",
    "experiment_name = \"ml_forecast'\n",
    "mlflow_path = \"./mlruns\"\n",
    "\n",
    "tags = {\n",
    "    'h':h,\n",
    "    'step_size':step_size,\n",
    "    'partitions':partitions,\n",
    "    'intervals_type': 'ConformalIntervals',\n",
    "    'intervals_h': h,\n",
    "    'intervals_n_windows': n_windows,\n",
    "    'intervals_method': 'conformal_distribution',\n",
    "    'levels': levels\n",
    "}\n",
    "\n",
    "# log backtesting results\n",
    "try:\n",
    "    mlflow.create_experiment(name=experiment_name,\n",
    "                             artifact_location=mlflow_path,\n",
    "                             tags=tags)\n",
    "    meta = mlflow.get_experiment_by_name(experiment_name)\n",
    "    print(f'Set a new experiment {experiment_name}')\n",
    "    print('Pulling the metadata')\n",
    "except:\n",
    "    print(f'Experiment {experiment_name} exists, pulling the metadata')\n",
    "    meta = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# run time\n",
    "run_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "for index, row in score_df.iterrows():\n",
    "    run_name - row['model_label'] + '_' + run_time\n",
    "    with mlflow.start_run(experiment_id=meta.experiment_id,\n",
    "                          run_name=run_name,\n",
    "                          tags= {'type': 'backtesting',\n",
    "                                 'partition': row['partition'],\n",
    "                                 'unique_id': row['unique_id'],\n",
    "                                 'model_label': row['model_label'],\n",
    "                                 'model_name': row['model_name'],\n",
    "                                 'run_name': run_name}) as run:\n",
    "        model_params = ml_models[row['model_label']].get_params()\n",
    "        model_params['model_name'] = row['model_name']\n",
    "        model_params['model_label'] = row['model_label']\n",
    "        model_params['partition'] = row['partition']\n",
    "        model_params['lags'] = list(range(1,24))\n",
    "        model_params['date_features'] = ['month', 'day', 'dayofweek', 'week', 'hour']\n",
    "        mlflow.log_params(model_params)\n",
    "        mlflow.log_metric('mape', row['mape'])\n",
    "        mlflow.log_metric('rmse', row['rmse'])\n",
    "        mlflow.log_metric('coverage', row['coverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the experiment name\n",
    "experiment_name = \"hyperparameter_tuning\"\n",
    "experiment_id = mlflow.create_experiment(experiment_name)\n",
    "\n",
    "# Loop through the DataFrame\n",
    "for idx, row in df.iterrows():\n",
    "  # Start a run\n",
    "  with mlflow.start_run(experiment_id=experiment_id):\n",
    "    model_params = ml_models[row[\"model_label\"]].get_params()\n",
    "    model_params[\"model_name\"] = row[\"model_name\"]\n",
    "    model_params[\"model_label\"] = row[\"model_label\"]\n",
    "    model_params[\"partition\"] = row[\"partition\"]\n",
    "    model_params[\"lags\"] = list(range(1, 24))\n",
    "    model_params[\"date_features\"] = [\"month\", \"day\", \"dayofweek\", \"week\", \"hour\"]\n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_metric(\"mape\", row[\"mape\"])\n",
    "    mlflow.log_metric(\"rmse\", row[\"rmse\"])\n",
    "    \n",
    "experiment_name = \"hyperparameter_tuning\"\n",
    "\n",
    "# Search MLflow runs\n",
    "all_results = mlflow.search_runs(experiment_names=[experiment_name])\n",
    "\n",
    "# Filter for the model with the best MAPE score\n",
    "best_mape_model = all_results.sort_values(\"metrics.mape\").head(1)\n",
    "\n",
    "# Print the model\n",
    "print(best_mape_model[[\"params.model_name\", \"metrics.mape\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f832d",
   "metadata": {},
   "source": [
    "run this in mlflow\n",
    "mlflow ui\n",
    "\n",
    "Model evaluation and selection\n",
    "1. benchmarking\n",
    "2. residual analysis\n",
    "3. backtesting analysis\n",
    "\n",
    "Potential improvements\n",
    "1. Different models\n",
    "2. New features\n",
    "3. Tuning hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4945a16",
   "metadata": {},
   "source": [
    "Since lightgbm performed best, we will proceed with it for hyperparameter tuning and final model training.\n",
    "\n",
    "Hypothesis\n",
    "1. Using lower learning rate and,\n",
    "2. training with more trees will improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_models2 = {\n",
    "    'lightgbm1': LGBMRegressor(n_estimators=100, learning_rate=0.1),\n",
    "    'lightgbm2': LGBMRegressor(n_estimators=250, learning_rate=0.1),\n",
    "    'ligthgbm3': LGBMRegressor(n_estimators=500, learning_rate=0.1),\n",
    "    'lightgbm4': LGBMRegressor(n_estimators=100, learning_rate=0.05),\n",
    "    'lightgbm5': LGBMRegressor(n_estimators=250, learning_rate=0.05),\n",
    "    'lightgbm6': LGBMRegressor(n_estimators=500, learning_rate=0.05),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8dfaf",
   "metadata": {},
   "source": [
    " Lightgbm6 seems good based on backtesting results. You can proceed or continue to tune based on computational resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7cf4e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57951682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
